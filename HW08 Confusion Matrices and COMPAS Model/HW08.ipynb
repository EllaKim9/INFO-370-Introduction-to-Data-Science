{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78658dc-8e84-4041-9ef0-0e6cb6cb7b61",
   "metadata": {},
   "source": [
    "# Info 370 HW 08\n",
    "\n",
    "Name: Ella Kim   \n",
    "\n",
    "*Citations are hyperlinked*\n",
    "\n",
    "## Is COMPAS fair? \n",
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dea34c1-3c0a-4428-94d6-c9adcf07c897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 8\n",
      "Number of rows: 6172\n",
      "   age c_charge_degree              race          age_cat   sex  priors_count  \\\n",
      "0   69               F             Other  Greater than 45  Male             0   \n",
      "1   34               F  African-American          25 - 45  Male             0   \n",
      "2   24               F  African-American     Less than 25  Male             4   \n",
      "3   44               M             Other          25 - 45  Male             0   \n",
      "4   41               F         Caucasian          25 - 45  Male            14   \n",
      "\n",
      "   decile_score  two_year_recid  \n",
      "0             1               0  \n",
      "1             3               1  \n",
      "2             4               1  \n",
      "3             1               0  \n",
      "4             6               1  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#load in data\n",
    "df_raw = pd.read_csv('/home/jovyan/lost+found/INFO_370/compas-score-data.csv.bz2', sep=\"\\t\")\n",
    "\n",
    "#sanity checks\n",
    "# print # cols\n",
    "cols = df_raw.shape[1]\n",
    "print(\"Number of columns: \" + str(cols))\n",
    "# print # rows\n",
    "rows = df_raw.shape[0]\n",
    "print(\"Number of rows: \" + str(rows))\n",
    "print(df_raw.head(5)) #sanity check\n",
    "# make df of total count of nulls in each col & print results\n",
    "df_null = df_raw.isnull().sum() # there are no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe48f1-c1b4-4d84-a465-f88d48e75745",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "199304a0-ad07-4625-a825-b384b0bc2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter raw df for only African American and Caucasian races\n",
    "df_compas = df_raw[(df_raw.race == \"African-American\") | (df_raw.race == \"Caucasian\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c95e6-5fae-4afb-8a3a-1eae99187fa3",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc1a56b7-58c5-4c73-9403-5f9e28a5a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy form to avoid warnings\n",
    "df_compas = df_compas.copy()\n",
    "\n",
    "(df_compas.decile_score <= 0).any().any() # no invalid values in column\n",
    "\n",
    "# make new column with catagory type of risk level with inequalities, value is inclusive to right bin\n",
    "df_compas[\"risk_cat\"] = pd.cut(df_compas.decile_score,\n",
    "                      bins = [-np.inf, 5, np.inf],\n",
    "                      labels = [\"low\", \"high\"],\n",
    "                      right=False)\n",
    "\n",
    "# df_compas.risk_cat.tolist() # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47bf89-5e51-4fb7-ac26-34b0b17d064f",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3967aa9d-2424-4f67-aa7e-5f53fdb080e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recidivism rate for low risk: 0.35481272654047524\n",
      "Recidivism rate for high risk: 0.6451872734595248\n",
      "\n",
      "Recidivism rate for African American: 0.6689488521949255\n",
      "Recidivism rate for Causaisan: 0.3310511478050745\n"
     ]
    }
   ],
   "source": [
    "# first filter df for only binary 1 for recidivism and get total count\n",
    "df_recidivism = df_compas[df_compas.two_year_recid == 1]\n",
    "n_total_recid = df_recidivism.shape[0]\n",
    "\n",
    "# A: compute recidivism rate vs risk\n",
    "# get count of each\n",
    "n_recid_low = df_recidivism[df_recidivism.risk_cat == \"low\"].shape[0]\n",
    "n_recid_high = df_recidivism[df_recidivism.risk_cat == \"high\"].shape[0]\n",
    "# compute and print rate\n",
    "print(\"Recidivism rate for low risk: \" + str(n_recid_low/n_total_recid))\n",
    "print(\"Recidivism rate for high risk: \" + str(n_recid_high/n_total_recid))\n",
    "\n",
    "# B: compute recidivism rate vs race\n",
    "# get count of each\n",
    "n_recid_afram = df_recidivism[df_recidivism.race == \"African-American\"].shape[0]\n",
    "n_recid_caucas = df_recidivism[df_recidivism.race == \"Caucasian\"].shape[0]\n",
    "# compute and print rate\n",
    "print(\"\\nRecidivism rate for African American: \" + str(n_recid_afram/n_total_recid))\n",
    "print(\"Recidivism rate for Causaisan: \" + str(n_recid_caucas/n_total_recid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03dcfa9-3e83-4726-8edf-e6a2f94abb18",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74b53e73-458f-4a35-8f16-33d8be52bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_cat         low  high\n",
      "two_year_recid            \n",
      "0               1872   923\n",
      "1                881  1602\n",
      "\n",
      "65.82% of individuals were accurately calssified by COMPAS (accuracy).\n",
      "\n",
      "64.52% of recidivism were correctly classified as high-risk (recall), or mirror image: \n",
      "63.45% of high risk individuals were correcly classified as recidivism (precision), or the mean of the two: \n",
      "63.98% average of high risk individuals and recidivism were correctly classified (F-score).\n",
      "\n",
      "35.48% of recidivism were falsly classified as low-risk, or mirror image: \n",
      "32.0% of low-risk individuals were falsly classified as recidivism.\n",
      "\n",
      "33.02% of no-recidivism were falsly classified as high-risk, or mirror image: \n",
      "36.55% of high-risk individuals were falsly classified as no-recidivism.\n"
     ]
    }
   ],
   "source": [
    "# make confusion matrix, first is row, 2nd is column \n",
    "cm = pd.crosstab(df_compas.two_year_recid, df_compas.risk_cat)\n",
    "print(cm) # print matrix\n",
    "\n",
    "# calculate different totals\n",
    "total = cm.sum().sum()\n",
    "[non_recid, recid] = cm.sum(axis = 1)\n",
    "# assign cells in matrix to variable names I understand\n",
    "tp = cm.iloc[1,1]\n",
    "tn = cm.iloc[0,0]\n",
    "fn = cm.iloc[1,0]\n",
    "fp = cm.iloc[0,1]\n",
    "\n",
    "# print results/answers for A,R,P,F and false rates\n",
    "print()\n",
    "print(str(round((tp+tn)/total * 100, 2)) + \"% of individuals were accurately calssified by COMPAS (accuracy).\\n\")\n",
    "print(str(round((tp/(recid)*100), 2)) + \"% of recidivism were correctly classified as high-risk (recall), or mirror image: \")\n",
    "print(str(round((tp/(tp+fp)* 100), 2)) + \"% of high risk individuals were correcly classified as recidivism (precision), or the mean of the two: \")\n",
    "print(str(round(2/((1/(tp/(recid)*100))+ (1/(tp/(tp+fp)* 100))), 2)) + \"% average of high risk individuals and recidivism were correctly classified (F-score).\\n\")\n",
    "\n",
    "print(str(round(((fn/recid)*100), 2)) + \"% of recidivism were falsly classified as low-risk, or mirror image: \")\n",
    "print(str(round(((fn/(tn+fn))*100), 2)) + \"% of low-risk individuals were falsly classified as recidivism.\\n\")\n",
    "print(str(round(((fp/non_recid)*100), 2)) + \"% of no-recidivism were falsly classified as high-risk, or mirror image: \")\n",
    "print(str(round(((fp/(tp+fp))*100), 2)) + \"% of high-risk individuals were falsly classified as no-recidivism.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e28dc0-e4cc-4c31-8d1a-8efcec76ebd4",
   "metadata": {},
   "source": [
    "#### 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1dc9e6-49ae-406b-a431-e7bab9d8b695",
   "metadata": {},
   "source": [
    "I would not feel comfortable at all with a judge to use COMPAS, as the error in both predicted and actual are all over 30%, which means in the actual US prison population, of the hundreds of thousands of people who are released each year, over a third of them are inaccurately classified. Before this step's compuations, I was already considering 1% error bad enough as, in proportion to population, that would mean ~1,000 individuals are inaccurately classified, which is a large number, so I would never consider over 30% error ever tolerable in any situation. As human judges also are not perfect and would have their own biases even if only implicit/unconsious, so I am rethinking my 1% tolerance as a maybe impossible rate to achieve at this time. I beleive I would be more flexible after seeing COMPAS catagorize, but I also do not want to change my fundamentals just because of a algorithm that makes the situation worse and dulls my opinions towards misclassification. I would hope that someday a error as low or much lower than 1% would become possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58f00b-1112-479c-8c77-55246d172351",
   "metadata": {},
   "source": [
    "#### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1add50f4-b88a-4016-80c2-cf2ad0e4cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race            African-American  Caucasian\n",
      "two_year_recid                             \n",
      "0                           1514       1281\n",
      "1                           1661        822\n",
      "\n",
      "COMPAS accurately classifies 47.69% of African Americans\n",
      "COMPAS accurately classifies 39.09% of Caucasians\n",
      "\n",
      "False recidivism rates: 45.83%\n",
      "False no-recidivism rates: 66.89%\n"
     ]
    }
   ],
   "source": [
    "# now repeat above for race vs recidivism\n",
    "cm_race = pd.crosstab(df_compas.two_year_recid, df_compas.race)\n",
    "print(cm_race) # print confusion matrix \n",
    "\n",
    "# calculate different totals\n",
    "[non_recid_race, recid_race] = cm_race.sum(axis = 1)\n",
    "[tot_afram, tot_cauc] = cm_race.sum(axis = 0)\n",
    "# assign cells in matrix to variable names I understand\n",
    "tp_race = cm_race.iloc[1,1]\n",
    "tn_race = cm_race.iloc[0,0]\n",
    "fn_race = cm_race.iloc[1,0]\n",
    "fp_race = cm_race.iloc[0,1]\n",
    "\n",
    "# print results/answers for accuracy and false rates\n",
    "# A\n",
    "print(\"\\nCOMPAS accurately classifies \" + str(round(tn_race/tot_afram * 100, 2)) + \"% of African Americans\")\n",
    "print(\"COMPAS accurately classifies \" + str(round(tp_race/tot_cauc * 100, 2)) + \"% of Caucasians\")\n",
    "\n",
    "# B \n",
    "print(\"\\nFalse recidivism rates: \" + str(round(fp_race/non_recid_race * 100, 2)) + \"%\")\n",
    "print(\"False no-recidivism rates: \" + str(round(fn_race/recid_race * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a973c-be73-46ed-bb47-6aadbe46ef8e",
   "metadata": {},
   "source": [
    "#### 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c7caf8-94dc-47d6-b920-338960761db5",
   "metadata": {},
   "source": [
    "The COMPAS algorithm is already questionable in the accuracy just based of scoring and recidivism, as it has over 30% error. Hoever, the fact that, based off of race and recidivism, COMPAS cannot even accurately classify at least 50% of races accurately and false positive and false negative rates are even higher than the last confusion matrix, makes me more certain that COMPAS is unfair, particularly racially. Seeing as the recidivism rates for African-Americans is ~ 66.89% and Caucasians is ~ 33.11% and with my prior knowledge from articles of COMPAS giving higher scores to African-Americans of no-recidivism and lower scores to Caucasians of recidivism, the data confirmed the discrepancies of recidivism based off of both score and race. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ca734-e766-413a-aa44-09c66788ed47",
   "metadata": {},
   "source": [
    "## Can you beat COMPAS?  \n",
    "#### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81b5a8-0ac7-4da9-bc35-282a1ec52d5a",
   "metadata": {},
   "source": [
    "While I like how APRF shows in count accuracy and error, as it is not sensitive to confidence of its estimators (and accuracy is what we care about here), I am the most comfortable with linear regression (or in this case with catagorical variables a logisitic regression), especially because we want to understand the dependence of recidivism rates on many variables/factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c855ff8-ddff-4a2e-8530-315a36592d92",
   "metadata": {},
   "source": [
    "#### 2\n",
    "\n",
    "[Cited formatting for cross_val_score](https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11e4f19c-2776-475a-a3a6-d629be0e4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correct catagorization: 67.19% (with standard dev = 1.68%)\n"
     ]
    }
   ],
   "source": [
    "# make X and y, X the different catagorical explanatory variables, y is the recidivism binary\n",
    "# do not include race sex, and numerical version of age because it relates to age_cat\n",
    "\n",
    "# make dummy with catagory type of prior crimes with inequalities, value is inclusive to right bin\n",
    "df_compas[\"prior_cat\"] = pd.cut(df_compas.priors_count,\n",
    "                      bins = [-np.inf, 1, 6, np.inf],\n",
    "                      labels = [\"0\", \"1-5\", \"6+\"],\n",
    "                      right=False)\n",
    "\n",
    "# make X df of explanatory and y of predicting variable\n",
    "X = df_compas[[\"age_cat\", \"c_charge_degree\", \"prior_cat\", \"risk_cat\"]]\n",
    "y = df_compas.two_year_recid.array\n",
    "# have to make X dummy bc not work below if not\n",
    "X = pd.get_dummies(X)\n",
    "# get ready cv (cross-validaiton)\n",
    "cvType = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "# assign model to use in cross_val\n",
    "useModel = LogisticRegression(solver = 'liblinear')\n",
    "# evaluate model\n",
    "result = cross_val_score(useModel, X, y, cv = cvType, n_jobs =-1)\n",
    "print(\"Percent of correct catagorization: \" + str(round(result.mean()*100, 2)) + \"% (with standard dev = \" + str(round(result.std()*100, 2)) + \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad06008-a7c7-4a8b-b13e-ff9dea2c2fdc",
   "metadata": {},
   "source": [
    "#### 3\n",
    "\n",
    "[Citation for making interaction effects (commented below)](https://stats.stackexchange.com/questions/105543/how-to-prepare-interactions-of-categorical-variables-in-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f08babfa-94a5-4181-b460-fe41ee59eece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correct catagorization: 68.49% (with standard dev = 2.1%)\n"
     ]
    }
   ],
   "source": [
    "# play around and make new variables for X and test them to see if accuracy increases in predictions\n",
    "\n",
    "# make prior cat with more bins\n",
    "df_compas[\"priors_cat\"] = pd.cut(df_compas.priors_count,\n",
    "                      bins = [-np.inf, 1, 3, 5, 7, np.inf],\n",
    "                      labels = [\"0\", \"1-2\", \"3-4\", \"5-6\", \"7+\"],\n",
    "                      right=False)\n",
    "\n",
    "df_compas[\"age_cat_more\"] = pd.cut(df_compas.age,\n",
    "                      bins = [18, 22, 26, 30, 34, 38, 42, np.inf],\n",
    "                      labels = [\"18-21\", \"22-25\", \"26-29\", \"30-33\", \"34-37\", \"38-41\", \"42+\"],\n",
    "                      right=False)\n",
    "\n",
    "\n",
    "# from patsy import dmatrices\n",
    "# did not improve, do not include \n",
    "# create dummy variables, and their interactions\n",
    "#y_1, X_1 = dmatrices('two_year_recid ~ C(c_charge_degree) + C(priors_cat) + C(age_cat_more) + C(risk_cat) + age', df_compas, return_type=\"dataframe\")\n",
    "# flatten y into a 1-D array so scikit-learn can understand it\n",
    "#y_1 = np.ravel(y)\n",
    "\n",
    "# change variable names to 3 to refer to problem 3 analysis\n",
    "# make X df of explanatory and y of predicting variable\n",
    "X_3 = df_compas[[\"age_cat_more\", \"c_charge_degree\", \"priors_cat\", \"risk_cat\"]]\n",
    "y_3 = df_compas.two_year_recid.array\n",
    "# have to make X_1 dummy bc not work below if not\n",
    "X_3 = pd.get_dummies(X_3)\n",
    "# get ready cv (cross-validaiton)\n",
    "cvType_3 = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "# assign model to use in cross_val\n",
    "useModel_3 = LogisticRegression(solver = 'liblinear')\n",
    "# evaluate model\n",
    "result_3 = cross_val_score(useModel_3, X_3, y_3, cv = cvType_3, n_jobs =-1)\n",
    "print(\"Percent of correct catagorization: \" + str(round(result_3.mean()*100, 2)) + \"% (with standard dev = \" + str(round(result_3.std()*100, 2)) + \"%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68462ae-9bb5-465e-8bb2-b63af8ca1de2",
   "metadata": {},
   "source": [
    "I attempted various things, some like the suggestions: I increased the number of catagories for the variables, and that increased the accuracy by ~1% (but also increased standard deviation), but any more number of catagories and the accuracy decreased it, and increasing of any other catagoriy levels (like docile score, priors_count, etc.) also decreased the accuracy. Any other attemps of removing 1-2 of the explanatory variables of various combinations and adding interaction effects between different variables, squaring age, etc. all resulted in a decrease in accuracy. I never used age catagory and age together because age catagory was directly related to age, which is a similar issue with removing the score_text variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186933d-e0cf-4694-8654-d06e70c02b0b",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80f57a8f-dcbf-4bae-8f24-656be0c16ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correct catagorization: 68.13% (with standard dev = 1.96%)\n"
     ]
    }
   ],
   "source": [
    "# make X df of explanatory (adding sex) and y of predicting variable\n",
    "X_4 = df_compas[[\"age_cat_more\", \"c_charge_degree\", \"priors_cat\", \"risk_cat\", \"sex\"]]\n",
    "y_4 = df_compas.two_year_recid.array\n",
    "# have to make X_1 dummy bc not work below if not\n",
    "X_4 = pd.get_dummies(X_4)\n",
    "# get ready cv (cross-validaiton)\n",
    "cvType_4 = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "# assign model to use in cross_val\n",
    "useModel_4 = LogisticRegression(solver = 'liblinear')\n",
    "# evaluate model\n",
    "result_4 = cross_val_score(useModel_4, X_4, y_4, cv = cvType_4, n_jobs =-1)\n",
    "print(\"Percent of correct catagorization: \" + str(round(result_4.mean()*100, 2)) + \"% (with standard dev = \" + str(round(result_4.std()*100, 2)) + \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b779f79-4bcd-4290-bfcf-b2d777307498",
   "metadata": {},
   "source": [
    "The accuracy of the model decreased, but not by much. The decrease in accuracy was followed by a decrease in standard deviation. So in conclusion, the model did not improve, but the worsening effect was not huge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19b088-8e2c-49c5-a5cc-b12f21e00d45",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdf179df-8c82-46ca-901f-a5546bc837ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of correct catagorization: 68.13% (with standard dev = 2.04%)\n"
     ]
    }
   ],
   "source": [
    "# make X df of explanatory (adding sex and race) and y of predicting variable\n",
    "X_5 = df_compas[[\"age_cat_more\", \"c_charge_degree\", \"priors_cat\", \"risk_cat\", \"sex\", \"race\"]]\n",
    "y_5 = df_compas.two_year_recid.array\n",
    "# have to make X_1 dummy bc not work below if not\n",
    "X_5 = pd.get_dummies(X_5)\n",
    "# get ready cv (cross-validaiton)\n",
    "cvType_5 = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "# assign model to use in cross_val\n",
    "useModel_5 = LogisticRegression(solver = 'liblinear')\n",
    "# evaluate model\n",
    "result_5 = cross_val_score(useModel_5, X_5, y_5, cv = cvType_5, n_jobs =-1)\n",
    "print(\"Percent of correct catagorization: \" + str(round(result_5.mean()*100, 2)) + \"% (with standard dev = \" + str(round(result_5.std()*100, 2)) + \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd34e0-0298-457d-8173-44009bbbc31b",
   "metadata": {},
   "source": [
    "The accuracy did not change, which intially made me think my code was wrong until I saw the increase in standard deviation. In conclusion, the addition of race does not seem to have a significant affect on the accuracy of the catagorization of this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9afa1c-df3d-4051-af53-d6e52f679eb5",
   "metadata": {},
   "source": [
    "#### 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb647c39-90f2-467c-b1bb-742c4e501129",
   "metadata": {},
   "source": [
    "Compared to the accuracy of the confusion matrixes of recidivism vs decile_score and race (65.82% and 44.26% respectively), the accuracy in the last model (68.13%) is larger. So I would say it is a better model than COMPAS. Although there is not much of an increase from recidivism vs docile_score to our model, I had to keep in mind that the comfusion matrix accuracy did not include race nor sex, so it is a significant improvement. Although gender and race decreased the overall accuracy, it was not a large decrease, so I would not say it worsened nor improved my predictions, if anything it kept it about the same. However, realistically, this accuracy is not even close to the ideal percentage I would want judges using. Although the accuracy is now a majority (> 50%) when also considering sex and race, I do not think judges should rely on this heavily for their decisons. While they could use it as a reference, I think there is much more to a person's charge than demographic or scores that would change the act recidivism and should be taken \"with a grain of salt.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e65b91-3e3b-486e-99e2-47e0f7f5cd8d",
   "metadata": {},
   "source": [
    "Hours spent: ~ 6 hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
